{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assets can be found at https://www.kaggle.com/c/word2vec-nlp-tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 25000 labeled train reviews, 25000 labeled test reviews, and 50000 unlabeled reviews\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read data from files\n",
    "train = pd.read_csv(\n",
    "    \"datasets/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3\n",
    ")\n",
    "\n",
    "test = pd.read_csv(\"datasets/testData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "\n",
    "unlabeled_train = pd.read_csv(\n",
    "    \"datasets/unlabeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3\n",
    ")\n",
    "\n",
    "# Verify the number of reviews that were read (100,000 in total)\n",
    "print(\n",
    "    \"Read %d labeled train reviews, %d labeled test reviews, \"\n",
    "    \"and %d unlabeled reviews\\n\"\n",
    "    % (train[\"review\"].size, test[\"review\"].size, unlabeled_train[\"review\"].size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import various modules for string cleaning\n",
    "import re\n",
    "import warnings\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup, MarkupResemblesLocatorWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def review_to_wordlist(review):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #\n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z0-9]\", \" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "\n",
    "# nltk.download()\n",
    "\n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "\n",
    "\n",
    "# Define a function to split a review into parsed sentences\n",
    "def review_to_sentences(review, tokenizer):\n",
    "    # Function to split a review into parsed sentences. Returns a\n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = list(\n",
    "        map(\n",
    "            lambda raw_sentence: review_to_wordlist(raw_sentence),\n",
    "            filter(lambda x: len(x) > 0, raw_sentences),\n",
    "        )\n",
    "    )\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n",
      "Parsing sentences from unlabeled set\n"
     ]
    }
   ],
   "source": [
    "sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "print(\"Parsing sentences from training set\")\n",
    "for review in train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "\n",
    "print(\"Parsing sentences from unlabeled set\")\n",
    "for review in unlabeled_train[\"review\"]:\n",
    "    sentences += review_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 08:50:26,630 : INFO : collecting all words and their counts\n",
      "2024-10-04 08:50:26,630 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-10-04 08:50:26,656 : INFO : PROGRESS: at sentence #10000, processed 227101 words, keeping 18037 word types\n",
      "2024-10-04 08:50:26,684 : INFO : PROGRESS: at sentence #20000, processed 454422 words, keeping 25321 word types\n",
      "2024-10-04 08:50:26,715 : INFO : PROGRESS: at sentence #30000, processed 674816 words, keeping 30471 word types\n",
      "2024-10-04 08:50:26,751 : INFO : PROGRESS: at sentence #40000, processed 902035 words, keeping 34850 word types\n",
      "2024-10-04 08:50:26,787 : INFO : PROGRESS: at sentence #50000, processed 1122616 words, keeping 38319 word types\n",
      "2024-10-04 08:50:26,825 : INFO : PROGRESS: at sentence #60000, processed 1345401 words, keeping 41326 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 08:50:26,865 : INFO : PROGRESS: at sentence #70000, processed 1569458 words, keeping 43964 word types\n",
      "2024-10-04 08:50:26,898 : INFO : PROGRESS: at sentence #80000, processed 1789870 words, keeping 46393 word types\n",
      "2024-10-04 08:50:26,929 : INFO : PROGRESS: at sentence #90000, processed 2015433 words, keeping 48855 word types\n",
      "2024-10-04 08:50:26,959 : INFO : PROGRESS: at sentence #100000, processed 2238378 words, keeping 50962 word types\n",
      "2024-10-04 08:50:26,989 : INFO : PROGRESS: at sentence #110000, processed 2458629 words, keeping 52867 word types\n",
      "2024-10-04 08:50:27,027 : INFO : PROGRESS: at sentence #120000, processed 2682003 words, keeping 54946 word types\n",
      "2024-10-04 08:50:27,057 : INFO : PROGRESS: at sentence #130000, processed 2909250 words, keeping 56731 word types\n",
      "2024-10-04 08:50:27,086 : INFO : PROGRESS: at sentence #140000, processed 3123021 words, keeping 58266 word types\n",
      "2024-10-04 08:50:27,123 : INFO : PROGRESS: at sentence #150000, processed 3349974 words, keeping 60028 word types\n",
      "2024-10-04 08:50:27,152 : INFO : PROGRESS: at sentence #160000, processed 3573220 words, keeping 61596 word types\n",
      "2024-10-04 08:50:27,182 : INFO : PROGRESS: at sentence #170000, processed 3798039 words, keeping 63100 word types\n",
      "2024-10-04 08:50:27,212 : INFO : PROGRESS: at sentence #180000, processed 4019541 words, keeping 64562 word types\n",
      "2024-10-04 08:50:27,240 : INFO : PROGRESS: at sentence #190000, processed 4245888 words, keeping 65879 word types\n",
      "2024-10-04 08:50:27,282 : INFO : PROGRESS: at sentence #200000, processed 4471813 words, keeping 67200 word types\n",
      "2024-10-04 08:50:27,317 : INFO : PROGRESS: at sentence #210000, processed 4693755 words, keeping 68523 word types\n",
      "2024-10-04 08:50:27,344 : INFO : PROGRESS: at sentence #220000, processed 4920610 words, keeping 69872 word types\n",
      "2024-10-04 08:50:27,370 : INFO : PROGRESS: at sentence #230000, processed 5143744 words, keeping 71141 word types\n",
      "2024-10-04 08:50:27,398 : INFO : PROGRESS: at sentence #240000, processed 5372041 words, keeping 72379 word types\n",
      "2024-10-04 08:50:27,429 : INFO : PROGRESS: at sentence #250000, processed 5587917 words, keeping 73602 word types\n",
      "2024-10-04 08:50:27,458 : INFO : PROGRESS: at sentence #260000, processed 5809032 words, keeping 74766 word types\n",
      "2024-10-04 08:50:27,487 : INFO : PROGRESS: at sentence #270000, processed 6030654 words, keeping 76081 word types\n",
      "2024-10-04 08:50:27,515 : INFO : PROGRESS: at sentence #280000, processed 6257234 words, keeping 77684 word types\n",
      "2024-10-04 08:50:27,543 : INFO : PROGRESS: at sentence #290000, processed 6481092 words, keeping 79177 word types\n",
      "2024-10-04 08:50:27,570 : INFO : PROGRESS: at sentence #300000, processed 6707188 words, keeping 80565 word types\n",
      "2024-10-04 08:50:27,598 : INFO : PROGRESS: at sentence #310000, processed 6932840 words, keeping 81896 word types\n",
      "2024-10-04 08:50:27,626 : INFO : PROGRESS: at sentence #320000, processed 7160456 words, keeping 83293 word types\n",
      "2024-10-04 08:50:27,654 : INFO : PROGRESS: at sentence #330000, processed 7383268 words, keeping 84543 word types\n",
      "2024-10-04 08:50:27,683 : INFO : PROGRESS: at sentence #340000, processed 7614044 words, keeping 85816 word types\n",
      "2024-10-04 08:50:27,711 : INFO : PROGRESS: at sentence #350000, processed 7838323 words, keeping 87006 word types\n",
      "2024-10-04 08:50:27,743 : INFO : PROGRESS: at sentence #360000, processed 8059111 words, keeping 88195 word types\n",
      "2024-10-04 08:50:27,773 : INFO : PROGRESS: at sentence #370000, processed 8287589 words, keeping 89313 word types\n",
      "2024-10-04 08:50:27,802 : INFO : PROGRESS: at sentence #380000, processed 8514968 words, keeping 90520 word types\n",
      "2024-10-04 08:50:27,833 : INFO : PROGRESS: at sentence #390000, processed 8745107 words, keeping 91583 word types\n",
      "2024-10-04 08:50:27,865 : INFO : PROGRESS: at sentence #400000, processed 8969599 words, keeping 92624 word types\n",
      "2024-10-04 08:50:27,894 : INFO : PROGRESS: at sentence #410000, processed 9191556 words, keeping 93624 word types\n",
      "2024-10-04 08:50:27,922 : INFO : PROGRESS: at sentence #420000, processed 9412795 words, keeping 94667 word types\n",
      "2024-10-04 08:50:27,952 : INFO : PROGRESS: at sentence #430000, processed 9642741 words, keeping 95716 word types\n",
      "2024-10-04 08:50:27,986 : INFO : PROGRESS: at sentence #440000, processed 9869703 words, keeping 96685 word types\n",
      "2024-10-04 08:50:28,020 : INFO : PROGRESS: at sentence #450000, processed 10095076 words, keeping 97851 word types\n",
      "2024-10-04 08:50:28,061 : INFO : PROGRESS: at sentence #460000, processed 10329655 words, keeping 98941 word types\n",
      "2024-10-04 08:50:28,101 : INFO : PROGRESS: at sentence #470000, processed 10557257 words, keeping 99795 word types\n",
      "2024-10-04 08:50:28,145 : INFO : PROGRESS: at sentence #480000, processed 10779419 words, keeping 100743 word types\n",
      "2024-10-04 08:50:28,205 : INFO : PROGRESS: at sentence #490000, processed 11006982 words, keeping 101840 word types\n",
      "2024-10-04 08:50:28,266 : INFO : PROGRESS: at sentence #500000, processed 11230148 words, keeping 102759 word types\n",
      "2024-10-04 08:50:28,327 : INFO : PROGRESS: at sentence #510000, processed 11456789 words, keeping 103723 word types\n",
      "2024-10-04 08:50:28,399 : INFO : PROGRESS: at sentence #520000, processed 11681178 words, keeping 104627 word types\n",
      "2024-10-04 08:50:28,451 : INFO : PROGRESS: at sentence #530000, processed 11907773 words, keeping 105476 word types\n",
      "2024-10-04 08:50:28,492 : INFO : PROGRESS: at sentence #540000, processed 12132540 words, keeping 106367 word types\n",
      "2024-10-04 08:50:28,533 : INFO : PROGRESS: at sentence #550000, processed 12358616 words, keeping 107254 word types\n",
      "2024-10-04 08:50:28,569 : INFO : PROGRESS: at sentence #560000, processed 12581979 words, keeping 108145 word types\n",
      "2024-10-04 08:50:28,613 : INFO : PROGRESS: at sentence #570000, processed 12811095 words, keeping 108952 word types\n",
      "2024-10-04 08:50:28,654 : INFO : PROGRESS: at sentence #580000, processed 13033974 words, keeping 109818 word types\n",
      "2024-10-04 08:50:28,699 : INFO : PROGRESS: at sentence #590000, processed 13261079 words, keeping 110709 word types\n",
      "2024-10-04 08:50:28,745 : INFO : PROGRESS: at sentence #600000, processed 13484602 words, keeping 111461 word types\n",
      "2024-10-04 08:50:28,800 : INFO : PROGRESS: at sentence #610000, processed 13707546 words, keeping 112357 word types\n",
      "2024-10-04 08:50:28,860 : INFO : PROGRESS: at sentence #620000, processed 13933358 words, keeping 113139 word types\n",
      "2024-10-04 08:50:28,902 : INFO : PROGRESS: at sentence #630000, processed 14157966 words, keeping 113932 word types\n",
      "2024-10-04 08:50:28,939 : INFO : PROGRESS: at sentence #640000, processed 14381357 words, keeping 114779 word types\n",
      "2024-10-04 08:50:28,968 : INFO : PROGRESS: at sentence #650000, processed 14607567 words, keeping 115569 word types\n",
      "2024-10-04 08:50:28,999 : INFO : PROGRESS: at sentence #660000, processed 14831458 words, keeping 116340 word types\n",
      "2024-10-04 08:50:29,027 : INFO : PROGRESS: at sentence #670000, processed 15057876 words, keeping 117086 word types\n",
      "2024-10-04 08:50:29,054 : INFO : PROGRESS: at sentence #680000, processed 15283254 words, keeping 117818 word types\n",
      "2024-10-04 08:50:29,085 : INFO : PROGRESS: at sentence #690000, processed 15506638 words, keeping 118606 word types\n",
      "2024-10-04 08:50:29,117 : INFO : PROGRESS: at sentence #700000, processed 15736787 words, keeping 119427 word types\n",
      "2024-10-04 08:50:29,147 : INFO : PROGRESS: at sentence #710000, processed 15958178 words, keeping 120076 word types\n",
      "2024-10-04 08:50:29,185 : INFO : PROGRESS: at sentence #720000, processed 16186985 words, keeping 120727 word types\n",
      "2024-10-04 08:50:29,222 : INFO : PROGRESS: at sentence #730000, processed 16411682 words, keeping 121471 word types\n",
      "2024-10-04 08:50:29,251 : INFO : PROGRESS: at sentence #740000, processed 16635389 words, keeping 122192 word types\n",
      "2024-10-04 08:50:29,283 : INFO : PROGRESS: at sentence #750000, processed 16856131 words, keeping 122862 word types\n",
      "2024-10-04 08:50:29,313 : INFO : PROGRESS: at sentence #760000, processed 17076001 words, keeping 123497 word types\n",
      "2024-10-04 08:50:29,343 : INFO : PROGRESS: at sentence #770000, processed 17303464 words, keeping 124279 word types\n",
      "2024-10-04 08:50:29,373 : INFO : PROGRESS: at sentence #780000, processed 17534423 words, keeping 125008 word types\n",
      "2024-10-04 08:50:29,404 : INFO : PROGRESS: at sentence #790000, processed 17762948 words, keeping 125706 word types\n",
      "2024-10-04 08:50:29,423 : INFO : collected 126187 word types from a corpus of 17901872 raw words and 796172 sentences\n",
      "2024-10-04 08:50:29,423 : INFO : Creating a fresh vocabulary\n",
      "2024-10-04 08:50:29,497 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=20 retains 24456 unique words (19.38% of original 126187, drops 101731)', 'datetime': '2024-10-04T08:50:29.497826', 'gensim': '4.3.3', 'python': '3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]', 'platform': 'Linux-6.8.0-45-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2024-10-04 08:50:29,498 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=20 leaves 17551356 word corpus (98.04% of original 17901872, drops 350516)', 'datetime': '2024-10-04T08:50:29.498418', 'gensim': '4.3.3', 'python': '3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]', 'platform': 'Linux-6.8.0-45-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2024-10-04 08:50:29,573 : INFO : deleting the raw counts dictionary of 126187 items\n",
      "2024-10-04 08:50:29,576 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2024-10-04 08:50:29,576 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 13103069.438250097 word corpus (74.7%% of prior 17551356)', 'datetime': '2024-10-04T08:50:29.576505', 'gensim': '4.3.3', 'python': '3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]', 'platform': 'Linux-6.8.0-45-generic-x86_64-with-glibc2.35', 'event': 'prepare_vocab'}\n",
      "2024-10-04 08:50:29,693 : INFO : estimated required memory for 24456 words and 1000 dimensions: 207876000 bytes\n",
      "2024-10-04 08:50:29,694 : INFO : resetting layer weights\n",
      "2024-10-04 08:50:29,784 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-10-04T08:50:29.784670', 'gensim': '4.3.3', 'python': '3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]', 'platform': 'Linux-6.8.0-45-generic-x86_64-with-glibc2.35', 'event': 'build_vocab'}\n",
      "2024-10-04 08:50:29,785 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 24456 vocabulary and 1000 features, using sg=0 hs=0 sample=0.001 negative=5 window=15 shrink_windows=True', 'datetime': '2024-10-04T08:50:29.785475', 'gensim': '4.3.3', 'python': '3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]', 'platform': 'Linux-6.8.0-45-generic-x86_64-with-glibc2.35', 'event': 'train'}\n",
      "2024-10-04 08:50:30,837 : INFO : EPOCH 0 - PROGRESS: at 3.68% examples, 465930 words/s, in_qsize 7, out_qsize 0\n",
      "2024-10-04 08:50:31,848 : INFO : EPOCH 0 - PROGRESS: at 7.32% examples, 467373 words/s, in_qsize 7, out_qsize 0\n",
      "2024-10-04 08:50:32,854 : INFO : EPOCH 0 - PROGRESS: at 10.57% examples, 452086 words/s, in_qsize 7, out_qsize 0\n",
      "2024-10-04 08:50:33,856 : INFO : EPOCH 0 - PROGRESS: at 13.79% examples, 443176 words/s, in_qsize 7, out_qsize 0\n",
      "2024-10-04 08:50:34,863 : INFO : EPOCH 0 - PROGRESS: at 17.97% examples, 461736 words/s, in_qsize 7, out_qsize 0\n",
      "2024-10-04 08:50:35,883 : INFO : EPOCH 0 - PROGRESS: at 21.05% examples, 450288 words/s, in_qsize 7, out_qsize 0\n",
      "2024-10-04 08:50:36,888 : INFO : EPOCH 0 - PROGRESS: at 24.06% examples, 442155 words/s, in_qsize 7, out_qsize 0\n",
      "2024-10-04 08:50:37,927 : INFO : EPOCH 0 - PROGRESS: at 27.48% examples, 440497 words/s, in_qsize 7, out_qsize 0\n"
     ]
    }
   ],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec\n",
    "# creates nice output messages\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO\n",
    ")\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 1000  # Word vector dimensionality\n",
    "min_word_count = 20  # Minimum word count\n",
    "num_workers = 4  # Number of threads to run in parallel\n",
    "context = 15  # Context window size\n",
    "downsampling = 1e-3  # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(\n",
    "    sentences,\n",
    "    workers=num_workers,\n",
    "    vector_size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context,\n",
    "    sample=downsampling,\n",
    ")\n",
    "\n",
    "# It can be helpful to create a meaningful model name and\n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"models/1000features_20minwords_15context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "model = Word2Vec.load(\"models/1000features_20minwords_15context\")\n",
    "\n",
    "\n",
    "def parallelize_reviews(reviews):\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        return list(executor.map(review_to_wordlist, reviews))\n",
    "\n",
    "clean_train_reviews = parallelize_reviews(train[\"review\"])\n",
    "clean_test_reviews = parallelize_reviews(test[\"review\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for K Means clustering:  52.82303833961487 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time()  # Start time\n",
    "\n",
    "# Set \"k\" (num_clusters) to be 1/5th of the vocabulary size, or an\n",
    "# average of 5 words per cluster\n",
    "word_vectors = model.wv.vectors\n",
    "num_clusters = int(len(word_vectors) / 5)\n",
    "\n",
    "\n",
    "# Initialize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans(n_clusters=num_clusters)\n",
    "idx = kmeans_clustering.fit_predict(word_vectors)\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Time taken for K Means clustering: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number\n",
    "word_centroid_map = dict(zip(model.wv.index_to_key, idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bag_of_centroids(wordlist, word_centroid_map):\n",
    "    #\n",
    "    # The number of clusters is equal to the highest cluster index\n",
    "    # in the word / centroid map\n",
    "    num_centroids = max(word_centroid_map.values()) + 1\n",
    "    #\n",
    "    # Pre-allocate the bag of centroids vector (for speed)\n",
    "    bag_of_centroids = np.zeros(num_centroids, dtype=\"float32\")\n",
    "    #\n",
    "    # Loop over the words in the review. If the word is in the vocabulary,\n",
    "    # find which cluster it belongs to, and increment that cluster count\n",
    "    # by one\n",
    "    for word in wordlist:\n",
    "        if word in word_centroid_map:\n",
    "            index = word_centroid_map[word]\n",
    "            bag_of_centroids[index] += 1\n",
    "    #\n",
    "    # Return the \"bag of centroids\"\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-allocate an array for the training set bags of centroids (for speed)\n",
    "train_centroids = np.zeros((train[\"review\"].size, num_clusters), dtype=\"float32\")\n",
    "\n",
    "# Transform the training set reviews into bags of centroids\n",
    "counter = 0\n",
    "for review in clean_train_reviews:\n",
    "    train_centroids[counter] = create_bag_of_centroids(review, word_centroid_map)\n",
    "    counter += 1\n",
    "\n",
    "# Repeat for test reviews\n",
    "test_centroids = np.zeros((test[\"review\"].size, num_clusters), dtype=\"float32\")\n",
    "\n",
    "counter = 0\n",
    "for review in clean_test_reviews:\n",
    "    test_centroids[counter] = create_bag_of_centroids(review, word_centroid_map)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Fit a random forest and extract predictions\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Fitting the forest may take a few minutes\n",
    "print(\"Fitting a random forest to labeled training data...\")\n",
    "forest = forest.fit(train_centroids, train[\"sentiment\"])\n",
    "result = forest.predict(test_centroids)\n",
    "\n",
    "# Write the test results\n",
    "output = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": result})\n",
    "output.to_csv(\"submissions/BagOfCentroids3.csv\", index=False, quoting=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
